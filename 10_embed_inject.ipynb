{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8816b366-5be4-4748-b769-4dc6f7d1735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the file 00_setup.py to define input/output file paths on your system\n",
    "# The information in 00_setup.py will be used across notebooks\n",
    "from importlib.machinery import SourceFileLoader\n",
    "setup = SourceFileLoader(\"setup\", \"./00_setup.py\").load_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945de0c-f042-46b2-9d06-ab064af6c05b",
   "metadata": {},
   "source": [
    "## Neural Network With NAICS Embedding Layer, Missing Values Injected in Fit\n",
    "Use NAICS entity embeddings, plus a custom data generate to randomly inject the unseen code (1) into training cases, in order to help the model learn how to handle missing information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a4288-a527-447f-9243-d0daea6d3bff",
   "metadata": {},
   "source": [
    "Encode only the base NAICS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169c2e8-ba0f-488f-acf6-87d419bd4e99",
   "metadata": {},
   "source": [
    "Use the dataset with no missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a7ec9-7d7b-47df-a902-b2f1e54f1135",
   "metadata": {},
   "source": [
    "*This script takes about 2 hours on my MacBook Air*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb42f9b4-99a8-4753-aacf-8722469be4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf51170a-4487-4d10-b63d-c88f41b529f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import importlib, pickle\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09dd973b-60a0-434b-9193-8c5fcec27dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b466e7-a419-45aa-83f7-5dafc7a3998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Input, Embedding, \\\n",
    "    Concatenate, Reshape, concatenate, Flatten\n",
    "import tensorflow.keras.metrics as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1e4f2e-0e45-4e28-8e9c-212e0bb51199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sba_nn.sba_nn import sbnn_metrics, sbnn_model\n",
    "from sba_nn.sba_nn.sbnn_model import CatInjectGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc00d2-bc83-42d9-83eb-65fcf306dccd",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e014cd31-0f8d-42e3-82f9-b529eec8a3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sba_loans = pd.read_parquet(Path(setup.temp_path).joinpath('01_DATA_transformed_nomiss.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e65cb7c-792c-46ff-a530-0d5c64240d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(setup.temp_path).joinpath('01_DATA_features.pkl'), 'rb') as fin:\n",
    "    imputer_features = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0ce28e-a80c-415b-b068-5c4d49370da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAICS': 1170,\n",
       " 'NAICS_5': 764,\n",
       " 'NAICS_4': 345,\n",
       " 'NAICS_3': 107,\n",
       " 'NAICS_sector': 21}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(Path(setup.temp_path).joinpath('01_DATA_naics_max_encodings.pkl'), 'rb') as fin:\n",
    "    naics_max_levels= pickle.load(fin)\n",
    "naics_max_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4116da-d689-478a-9c5d-a330f231e615",
   "metadata": {},
   "source": [
    "##### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f98c6e41-38d0-4d5f-b821-e3837b8c2068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NoEmp', 'CreateJob', 'LowDoc', 'DisbursementGross', 'new_business', 'urban_flag', 'franchise_flag', 'missingindicator_LowDoc', 'missingindicator_new_business', 'missingindicator_urban_flag']\n"
     ]
    }
   ],
   "source": [
    "# Numeric features\n",
    "features_numeric = [f for f in imputer_features if 'NAICS' not in f]\n",
    "features_numeric_len = len(features_numeric)\n",
    "print(features_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74fa386-4011-45ee-bdb5-d671db9ffa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAICS feature - just bas\n",
    "features_naics = ['NAICS']\n",
    "features_naics_max_levels  = [naics_max_levels[n] for n in features_naics]\n",
    "features_naics_emb_dim = [setup.nn_naics_embed_size_dict[n] for n in features_naics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867031ee-8b6e-424d-b497-8e19409ba1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1170]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "print(features_naics_max_levels)\n",
    "print(features_naics_emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979396c-c822-4940-a292-6e07f1b54f58",
   "metadata": {},
   "source": [
    "##### Datasets for train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43bca011-a59d-4496-9f03-87f4e350a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sba_loans[['dset', 'LoanNr_ChkDgt'] + features_numeric].set_index('LoanNr_ChkDgt').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa162d01-ed73-4ae3-832e-4aeea09b70f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training X: (446848, 10), y:(446848,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[X['dset'] == 'train'].drop(columns='dset')\n",
    "y_train = sba_loans[sba_loans['dset'] == 'train'].set_index('LoanNr_ChkDgt').sort_index()['target']\n",
    "print(f'training X: {X_train.shape}, y:{y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b32b5fd3-6f6e-4aec-8e20-0e2b71a4814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val X: (95604, 10), y:(95604,)\n"
     ]
    }
   ],
   "source": [
    "X_val = X[X['dset'] == 'val'].drop(columns='dset')\n",
    "y_val = sba_loans[sba_loans['dset'] == 'val'].set_index('LoanNr_ChkDgt').sort_index()['target']\n",
    "print(f'val X: {X_val.shape}, y:{y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01b8ff96-159b-4283-b5fb-c4b5dbd277d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20230592953308507\n"
     ]
    }
   ],
   "source": [
    "base_thresh = y_train.mean()\n",
    "print(base_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b8ce4c9-6907-4b70-982a-b92a52b3159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_naics = [sba_loans[['dset', 'LoanNr_ChkDgt', n]].set_index('LoanNr_ChkDgt').sort_index() \\\n",
    "           for n in features_naics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f129e0-a4d0-4d93-9886-153c9803d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_naics_train = [Xn[Xn['dset'] == 'train'].drop(columns='dset') for Xn in X_naics]\n",
    "X_naics_val =  [Xn[Xn['dset'] == 'val'].drop(columns='dset') for Xn in X_naics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4ea1c-77b2-4721-b106-1e66fc502139",
   "metadata": {},
   "source": [
    "## Create, fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d48ddfa-580c-4321-9917-0bd176b67d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 22:12:25.968390: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-05-17 22:12:25.968439: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-05-17 22:12:25.968446: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-05-17 22:12:25.968545: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-17 22:12:25.968577: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "this_model = sbnn_model.create_emb_model(features_numeric_len,\n",
    "                                         features_naics_max_levels,\n",
    "                                         features_naics_emb_dim,\n",
    "                                         naics_embedding_names = features_naics,\n",
    "                                         hidden_size = setup.nn_layer_sizes,\n",
    "                                         activation='tanh',\n",
    "                                         lr=setup.nn_learning_rate,\n",
    "                                         opt_func = setup.nn_optimizer,\n",
    "                                         dropout = setup.nn_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47036621-ef13-4957-997b-f8ef86016f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_naics_00 (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " emb_naics_00 (Embedding)    (None, 1, 8)                 9360      ['input_naics_00[0][0]']      \n",
      "                                                                                                  \n",
      " NAICS (Flatten)             (None, 8)                    0         ['emb_naics_00[0][0]']        \n",
      "                                                                                                  \n",
      " input_numeric (InputLayer)  [(None, 10)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_concat (Concatenate)  (None, 18)                   0         ['NAICS[0][0]',               \n",
      "                                                                     'input_numeric[0][0]']       \n",
      "                                                                                                  \n",
      " layer_00 (Dense)            (None, 128)                  2432      ['input_concat[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_00 (Dropout)        (None, 128)                  0         ['layer_00[0][0]']            \n",
      "                                                                                                  \n",
      " layer_01 (Dense)            (None, 64)                   8256      ['dropout_00[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_01 (Dropout)        (None, 64)                   0         ['layer_01[0][0]']            \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 1)                    65        ['dropout_01[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20113 (78.57 KB)\n",
      "Trainable params: 20113 (78.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "this_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7408d-99ce-413e-aef8-23743b5601cd",
   "metadata": {},
   "source": [
    "##### Use data generator to inject 1 values into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a808a122-ceed-4bbe-a259-ffb21371a71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feature_index = [i for i in range(1, len(X_naics_train)+1)]\n",
    "cat_feature_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f25b59fc-8828-4a4e-b44b-478562c7e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sbnn_model)\n",
    "from sba_nn.sba_nn.sbnn_model import CatInjectGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1dfde86-af9b-4110-aae9-30f3d59404af",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = CatInjectGenerator(pd.concat([X_train]+ X_naics_train, axis=1), \n",
    "                               y_train,\n",
    "                               categorical_columns=features_naics,\n",
    "                               batch_size = setup.nn_batch_size)\n",
    "                               #inject_value = 1,\n",
    "                               #inject_fraction = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ebbdb-daae-45c7-bbe2-751f8c245c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8012/13964 [================>.............] - ETA: 1:07 - loss: 0.4523 - auc: 0.3701 - auc_1: 0.7224"
     ]
    }
   ],
   "source": [
    "this_history = this_model.fit(generator,\n",
    "                              batch_size=setup.nn_batch_size,\n",
    "                              epochs = 1,\n",
    "                              validation_data=([X_val] + X_naics_val, y_val),\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e98b8-4345-4f3d-b644-60904daaeb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31772016-3643-468b-8d65-c456168cad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 32\n",
      "batch shapes: 32 32\n",
      "32\n",
      "batch size: 32\n",
      "batch shapes: 32 32\n",
      "32\n",
      "batch size: 32\n",
      "batch shapes: 32 32\n",
      "32\n",
      "batch size: 32\n",
      "batch shapes: 32 32\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 21:47:45.446168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-05-17 21:47:45.545315: W tensorflow/core/framework/op_kernel.cc:1816] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n",
      "\n",
      "\n",
      "2024-05-17 21:47:45.545439: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6438432652975368686\n",
      "2024-05-17 21:47:45.545450: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1669268878216410622\n",
      "2024-05-17 21:47:45.545455: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 7490276661033127450\n",
      "2024-05-17 21:47:45.545460: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 1399320457330839266\n",
      "2024-05-17 21:47:45.545464: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9910002793771916091\n",
      "2024-05-17 21:47:45.546207: W tensorflow/core/framework/op_kernel.cc:1816] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n",
      "\n",
      "\n",
      "2024-05-17 21:47:45.546835: W tensorflow/core/framework/op_kernel.cc:1816] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[model/Cast_1/_10]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1415]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m this_history \u001b[38;5;241m=\u001b[39m \u001b[43mthis_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_naics_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_p38/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[model/Cast_1/_10]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/valeriecarey/miniconda3/envs/tf_p38/lib/python3.8/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (32,) where an element of shape (None, None) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1415]"
     ]
    }
   ],
   "source": [
    "this_history = this_model.fit(generator,\n",
    "                              validation_data=([X_val] + X_naics_val, y_val),\n",
    "                              batch_size=setup.nn_batch_size,\n",
    "                              epochs = 1)\n",
    "                              #epochs=setup.nn_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b161b9e-7116-4275-8586-c104ecb195eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup.nn_batch_size,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c4b43-c673-4ee1-b070-d2d596ac4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_history_df = sbnn_model.process_history(this_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4783f2-8d0b-4850-a45a-3a4be8e63318",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_history_df.to_csv(Path(setup.temp_path).joinpath('10_REPORT_fit_history.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e89efd-75a9-4b27-81a8-13e12d5482be",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_history_df[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342a31f-4891-4834-851a-b90b8b729c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_history_df[['auc', 'val_auc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee80637-cabf-4974-b476-08c5fba165ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_history_df[['auc_roc', 'val_auc_roc']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184b0ca-1d31-4798-88a0-4e590b67062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_model.save(Path(setup.temp_path).joinpath('10_DATA_model.keras'),save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326c9ea-4759-4418-a64d-56c151049c25",
   "metadata": {},
   "source": [
    "## Predictions on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c39a5a-dc19-4606-b744-34865bc6c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_naics = [sba_loans[['dset', 'LoanNr_ChkDgt', n]].set_index('LoanNr_ChkDgt').sort_index() \\\n",
    "           for n in features_naics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6910ee-5ffe-4def-9aa8-7dba76446b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = this_model.predict([X.drop(columns='dset')] +\n",
    "                                     [Xn.drop(columns='dset') for Xn in X_naics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2cce1-b7d3-4ebc-8869-80705297e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_df = pd.DataFrame(all_predictions, index=X.index) \\\n",
    "    .set_axis(['predict_prob'], axis=1) \\\n",
    "    .reset_index() \\\n",
    "    .merge(sba_loans[['target', 'LoanNr_ChkDgt', 'dset', 'dset_naics_holdout', 'NAICS']], \n",
    "           on='LoanNr_ChkDgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7da9c-6bd2-4d1b-b77f-b62679825d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_df[['predict_prob', 'target']].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79afc4e-cb67-4064-9b19-dc52500baef2",
   "metadata": {},
   "source": [
    "##### Threshold Tune & Binary Predictions\n",
    "Using training probability predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0bc23-fbc0-40d0-8d8b-f2302405a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred_train = all_predictions_df[all_predictions_df['dset'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36d9e9-f35e-46b3-a5be-08081f998319",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_tune_data = sbnn_metrics.get_f1_frame(all_pred_train['target'], \n",
    "                                        all_pred_train['predict_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de634156-caf6-4a52-b5d7-44b8e986aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_tune_data.sort_values('f1', ascending=False, inplace=True)\n",
    "thresh_tune_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746b880-d781-4bc1-9df2-89211127c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh = thresh_tune_data['thresh'].iloc[0]\n",
    "best_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac5e2-be0d-42f0-960d-1f81b4a5d4e2",
   "metadata": {},
   "source": [
    "##### Append binary predictions to probability predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641da72e-1bca-4fe7-96c4-6c029b521bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_df['predict_bin'] = sbnn_metrics.get_binary_predictions(all_predictions_df['predict_prob'], best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ecdf4-ac01-4c39-8315-e8583daa337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_df['predict_bin'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfed830-7ff8-40f6-a691-6b894b26d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_df.to_parquet(Path(setup.temp_path).joinpath('10_DATA_predictions.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ecbd2-abff-46d8-8c70-f7bccd363b69",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ceefe-c7a8-45bd-8573-2daefe99a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dset_df = all_predictions_df.groupby('dset') \\\n",
    "    .apply(lambda x: sbnn_metrics.dset_metrics(x.target, x.predict_bin, x.predict_prob)) \\\n",
    "    .reset_index()\n",
    "metrics_test_df = all_predictions_df[all_predictions_df['dset'] == 'test'] \\\n",
    "    .groupby(['dset', 'dset_naics_holdout']) \\\n",
    "    .apply(lambda x: sbnn_metrics.dset_metrics(x.target, x.predict_bin, x.predict_prob)) \\\n",
    "    .reset_index()\n",
    "metrics_df = pd.concat([metrics_dset_df, metrics_test_df])\n",
    "metrics_df.to_csv(Path(setup.temp_path).joinpath('10_REPORT_metrics.csv'), index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e382b5-e9dc-47a1-9bf4-6d0b6b4a0c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_p39",
   "language": "python",
   "name": "tf_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
